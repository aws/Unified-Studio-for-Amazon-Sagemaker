{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters cell - will be replaced by Papermill\n",
    "mlflow_tracking_server_arn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import numpy as np\n",
    "from sagemaker.serve import SchemaBuilder, ModelBuilder\n",
    "from sagemaker.serve.mode.function_pointers import Mode\n",
    "\n",
    "print(\"üöÄ Starting Model Deployment and Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_studio import Project\n",
    "\n",
    "# Get IAM role from connection\n",
    "proj = Project()\n",
    "iam_conn = proj.connection('default.iam')\n",
    "role = iam_conn.iam_role\n",
    "print(f\"‚úÖ IAM Role: {role}\")\n",
    "\n",
    "# Validate MLflow ARN\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise ValueError(\"mlflow_tracking_server_arn parameter is required\")\n",
    "\n",
    "print(f\"‚úÖ MLflow ARN: {mlflow_tracking_server_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MLflow and retrieve trained model\n",
    "print(\"\\nüì¶ Retrieving model from MLflow...\")\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "client = MlflowClient()\n",
    "\n",
    "model_name = \"realistic-classifier-v1\"\n",
    "registered_model = client.get_registered_model(name=model_name)\n",
    "\n",
    "# Get champion model version\n",
    "champion_version = client.get_model_version_by_alias(model_name, \"champion\")\n",
    "source_path = champion_version.source\n",
    "\n",
    "print(f\"‚úÖ Model: {model_name}\")\n",
    "print(f\"‚úÖ Version: {champion_version.version}\")\n",
    "print(f\"‚úÖ Source: {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model schema\n",
    "print(\"\\nüîß Building model schema...\")\n",
    "\n",
    "sklearn_input = np.random.randn(1, 20)  # 20 features\n",
    "sklearn_output = 0  # Classification output\n",
    "\n",
    "schema_builder = SchemaBuilder(\n",
    "    sample_input=sklearn_input,\n",
    "    sample_output=sklearn_output,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Schema built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model for deployment\n",
    "print(\"\\nüèóÔ∏è  Building model for deployment...\")\n",
    "\n",
    "model_builder = ModelBuilder(\n",
    "    mode=Mode.SAGEMAKER_ENDPOINT,\n",
    "    schema_builder=schema_builder,\n",
    "    role_arn=role,\n",
    "    model_metadata={\"MLFLOW_MODEL_PATH\": source_path},\n",
    ")\n",
    "\n",
    "built_model = model_builder.build()\n",
    "print(\"‚úÖ Model built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to endpoint\n",
    "print(\"\\nüöÄ Deploying model to SageMaker endpoint...\")\n",
    "\n",
    "predictor = built_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "print(f\"‚úÖ Endpoint deployed: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print(\"\\nüîÆ Running inference...\")\n",
    "\n",
    "test_input = np.random.randn(1, 20)\n",
    "prediction = predictor.predict(test_input)\n",
    "\n",
    "print(f\"‚úÖ Prediction: {prediction}\")\n",
    "print(\"‚úÖ Inference successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources\n",
    "print(\"\\nüßπ Cleaning up resources...\")\n",
    "\n",
    "try:\n",
    "    predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "    print(f\"‚úÖ Deleted endpoint: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Cleanup error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Deployment and inference workflow completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
