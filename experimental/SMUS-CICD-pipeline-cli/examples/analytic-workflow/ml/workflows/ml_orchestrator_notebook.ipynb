{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Orchestrator Notebook\n",
    "This notebook orchestrates the complete ML pipeline using SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "import mlflow\n",
    "\n",
    "print(\"\ud83d\ude80 Starting Complete ML Pipeline Orchestration with Real SageMaker SDK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_studio import Project, ClientConfig\n",
    "\n",
    "# Get project connections dynamically\n",
    "# Get region from execution environment\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "client_config = ClientConfig(region=region, overrides={\"datazone\":{\"endpoint_url\":f\"https://iceland-gamma.{region}.api.aws\"}})\n",
    "proj = Project(config=client_config)\n",
    "\n",
    "# Get region from boto3 session\n",
    "region = boto3.Session().region_name\n",
    "print(f\"\u2705 Region: {region}\")\n",
    "\n",
    "# Get S3 shared bucket from connection\n",
    "s3_shared_conn = proj.connection('default.s3_shared')\n",
    "bucket = s3_shared_conn.data.s3_uri.rstrip('/').split('/')[-2]  # Extract bucket name\n",
    "print(f\"\u2705 S3 Bucket from connection: {bucket}\")\n",
    "\n",
    "# Get IAM role from connection\n",
    "iam_conn = proj.connection('default.iam')\n",
    "role = iam_conn.iam_role\n",
    "print(f\"\u2705 IAM Role from connection: {role}\")\n",
    "\n",
    "# Try to get MLflow connection (may not exist in all projects)\n",
    "try:\n",
    "    mlflow_conn = proj.connection('project.mlflow-server.mlflow')\n",
    "    mlflow_arn = mlflow_conn.mlflow_properties\n",
    "    print(f\"\u2705 MLflow ARN from connection: {mlflow_arn}\")\n",
    "except Exception as e:\n",
    "    mlflow_arn = None\n",
    "    print(f\"\u26a0\ufe0f  error {e}, using hard-coded MLflow integration: {mlflow_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic training and inference data\n",
    "print(\"\\n\ud83d\udcca Generating synthetic training and inference data...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate training data\n",
    "np.random.seed(42)\n",
    "X_train = np.random.randn(1000, 20)\n",
    "y_train = np.random.choice([0, 1, 2], 1000)\n",
    "train_df = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(20)])\n",
    "train_df['target'] = y_train\n",
    "\n",
    "# Generate inference data (no target column)\n",
    "np.random.seed(123)\n",
    "X_test = np.random.randn(100, 20)\n",
    "test_df = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(20)])\n",
    "\n",
    "# Upload to S3\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Save and upload training data\n",
    "train_local = '/tmp/training_data.csv'\n",
    "train_df.to_csv(train_local, index=False)\n",
    "train_s3_key = 'shared/ml/bundle/training-data/training_data.csv'\n",
    "s3_client.upload_file(train_local, bucket, train_s3_key)\n",
    "print(f\"\u2705 Uploaded training data to s3://{bucket}/{train_s3_key}\")\n",
    "\n",
    "# Save and upload inference data\n",
    "test_local = '/tmp/inference_data.csv'\n",
    "test_df.to_csv(test_local, index=False)\n",
    "test_s3_key = 'shared/ml/bundle/inference-data/inference_data.csv'\n",
    "s3_client.upload_file(test_local, bucket, test_s3_key)\n",
    "print(f\"\u2705 Uploaded inference data to s3://{bucket}/{test_s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_name = \"realistic-classifier-v1\"\n",
    "\n",
    "# MLflow setup (only if available)\n",
    "if mlflow_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_arn)\n",
    "    print(f\"\u2705 MLflow tracking enabled: {mlflow_arn}\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  MLflow tracking disabled (no connection)\")\n",
    "\n",
    "# Create SageMaker session\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Configuration:\")\n",
    "print(f\"  Region: {region}\")\n",
    "print(f\"  Bucket: {bucket}\")\n",
    "print(f\"  Role: {role}\")\n",
    "print(f\"  Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Training with Real SageMaker SDK\n",
    "print(\"\\n\ud83d\udcc8 Step 1: Real Model Training with SageMaker SDK\")\n",
    "\n",
    "# Build environment variables (only add MLflow if available)\n",
    "env_vars = {}\n",
    "if mlflow_arn:\n",
    "    env_vars[\"MLFLOW_TRACKING_SERVER_ARN\"] = mlflow_arn\n",
    "\n",
    "source_dir = f's3://{bucket}/shared/ml/bundle/training-code/training-code.tar.gz'\n",
    "training_data = f's3://{bucket}/shared/ml/bundle/training-data/'\n",
    "output_path = f's3://{bucket}/shared/ml/output/model-artifacts/'\n",
    "\n",
    "print(f\"  Training code: {source_dir}\")\n",
    "print(f\"  Training data: {training_data}\")\n",
    "print(f\"  Output path: {output_path}\")\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='sagemaker_training_script.py',\n",
    "    source_dir=source_dir,\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    output_path=output_path,\n",
    "    environment=env_vars,\n",
    "    hyperparameters={\n",
    "        'n-estimators': 100, \n",
    "        'max-depth': 10, \n",
    "        'random-state': 42,\n",
    "        'model-name': model_name\n",
    "    }\n",
    ")\n",
    "\n",
    "job_name = f\"orchestrated-training-{int(time.time())}\"\n",
    "print(f\"Starting real training job: {job_name}\")\n",
    "\n",
    "# This will create a real SageMaker training job\n",
    "sklearn_estimator.fit(\n",
    "    inputs={'training': training_data},\n",
    "    job_name=job_name\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Real training completed: {sklearn_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Champion Model Tagging with Real MLflow\n",
    "print(\"\\n\ud83c\udfc6 Step 2: Real Champion Model Tagging\")\n",
    "champion_tagged = False\n",
    "\n",
    "if not mlflow_arn:\n",
    "    print(\"\u26a0\ufe0f  Skipping champion tagging (no MLflow connection)\")\n",
    "else:\n",
    "    try:\n",
    "        client = mlflow.MlflowClient()\n",
    "        \n",
    "        # Get latest model version\n",
    "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if versions:\n",
    "            latest_version = max(versions, key=lambda x: int(x.version))\n",
    "            client.set_registered_model_alias(\n",
    "                name=model_name,\n",
    "                alias=\"champion\",\n",
    "                version=latest_version.version\n",
    "            )\n",
    "            print(f\"\u2705 Real champion tagging: version {latest_version.version}\")\n",
    "            champion_tagged = True\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  No model versions found, will be created by training job\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Champion tagging will happen after training job completes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Real Batch Transform\n",
    "print(\"\ud83d\udd04 Step 3: Real Batch Inference with SageMaker SDK\")\n",
    "\n",
    "try:\n",
    "    # Create model with CSV output configuration\n",
    "    model = sklearn_estimator.create_model()\n",
    "    model.env = {\n",
    "        'MODEL_SERVER_TIMEOUT': '60',\n",
    "        'MODEL_SERVER_WORKERS': '1',\n",
    "        'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv'\n",
    "    }\n",
    "    \n",
    "    transformer = model.transformer(\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.large',\n",
    "        output_path=f's3://{bucket}/shared/ml/output/inference-results/'\n",
    "    )\n",
    "    \n",
    "    transform_job_name = f\"orchestrated-inference-{int(time.time())}\"\n",
    "    print(f\"Starting real batch transform: {transform_job_name}\")\n",
    "    \n",
    "    transformer.transform(\n",
    "        data=f's3://{bucket}/shared/ml/bundle/inference-data/',\n",
    "        content_type='text/csv',\n",
    "        split_type='Line',\n",
    "        job_name=transform_job_name,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\u2705 Real batch inference completed: {transformer.output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Batch transform failed: {type(e).__name__}: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    transform_job_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save Real Orchestration Results\n",
    "results = {\n",
    "    \"orchestration_type\": \"real_ml_pipeline_with_sagemaker_sdk\",\n",
    "    \"pipeline_steps\": [\n",
    "        \"real_sagemaker_training\",\n",
    "        \"real_mlflow_integration\", \n",
    "        \"real_champion_tagging\",\n",
    "        \"real_batch_inference\"\n",
    "    ],\n",
    "    \"training_job\": job_name,\n",
    "    \"transform_job\": transform_job_name,\n",
    "    \"model_artifacts\": sklearn_estimator.model_data,\n",
    "    \"inference_results\": transformer.output_path,\n",
    "    \"mlflow_tracking\": mlflow_arn,\n",
    "    \"model_name\": model_name,\n",
    "    \"champion_tagged\": champion_tagged,\n",
    "    \"sagemaker_sdk_used\": True,\n",
    "    \"real_jobs_created\": True,\n",
    "    \"execution_timestamp\": int(time.time()),\n",
    "    \"status\": \"SUCCESS\"\n",
    "}\n",
    "\n",
    "print(\"\\n\ud83c\udf89 Real ML Pipeline Orchestration with SageMaker SDK Completed!\")\n",
    "print(f\"Real Training Job: {job_name}\")\n",
    "print(f\"Real Transform Job: {transform_job_name}\")\n",
    "print(f\"Real Model Artifacts: {sklearn_estimator.model_data}\")\n",
    "print(f\"Real Inference Results: {transformer.output_path}\")\n",
    "print(f\"MLflow Integration: ENABLED via SageMaker SDK\")\n",
    "print(f\"Champion Model: {model_name}@champion\")\n",
    "\n",
    "# Save results\n",
    "with open('/opt/ml/output/orchestration_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n\ud83d\udcca Results saved to /opt/ml/output/orchestration_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}