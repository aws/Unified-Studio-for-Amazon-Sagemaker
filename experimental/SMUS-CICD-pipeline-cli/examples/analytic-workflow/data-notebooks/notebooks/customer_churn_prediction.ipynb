{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Customer Churn Prediction: Saving Customers Before They Leave\n",
    "\n",
    "## ğŸ“Š The Business Challenge\n",
    "**Imagine this scenario:** Every month, your telecom company loses valuable customers to competitors. Each lost customer represents:\n",
    "- ğŸ’° **$50-200** in monthly recurring revenue\n",
    "- ğŸ”„ **5-10x** the cost to acquire a new customer vs. retaining existing ones\n",
    "- ğŸ“‰ **Negative word-of-mouth** that affects brand reputation\n",
    "\n",
    "## ğŸš€ Our Mission\n",
    "Build a machine learning-powered early warning system that identifies at-risk customers **before** they churn, enabling proactive retention strategies.\n",
    "\n",
    "### ğŸ“ˆ Expected Outcomes\n",
    "- Identify **high-risk customers** with 95%+ accuracy\n",
    "- Reduce churn rate by **15-25%**\n",
    "- Increase customer lifetime value by **$500-1000** per saved customer\n",
    "- Enable **targeted retention campaigns** instead of blanket approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:36.862422Z",
     "start_time": "2025-08-17T17:39:36.857900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "np.random.seed(2)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ğŸ¨ Make our visualizations beautiful\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print('ğŸ“Š Ready to uncover customer insights...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Chapter 1: The Customer Data Detective Story\n",
    "\n",
    "Let's dive into our customer database and uncover the secrets hidden in the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.232150Z",
     "start_time": "2025-08-17T17:39:36.881651Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ“¥ Load our customer intelligence database\n",
    "session = boto3.Session()\n",
    "aws_region = session.region_name or 'us-west-2'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('notebook_outputs', exist_ok=True)\n",
    "\n",
    "s3.download_file(\n",
    "    f'sagemaker-example-files-prod-{aws_region}',\n",
    "    'datasets/tabular/synthetic/churn.txt',\n",
    "    'notebook_outputs/churn.txt'\n",
    ")\n",
    "\n",
    "df = pd.read_csv('notebook_outputs/churn.txt')\n",
    "\n",
    "print('ğŸ¯ Customer Database Loaded!')\n",
    "print(f'ğŸ“Š We have {df.shape[0]:,} customers with {df.shape[1]} data points each')\n",
    "print(f'ğŸ’¾ Total data points: {df.shape[0] * df.shape[1]:,}')\n",
    "\n",
    "# ğŸ” First glimpse at our customers\n",
    "print('\\nğŸ‘¥ Meet our first 5 customers:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.324745Z",
     "start_time": "2025-08-17T17:39:37.267653Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Calculate the churn crisis metrics\n",
    "total_customers = len(df)\n",
    "churned_customers = len(df[df['Churn?'] == 'True.'])\n",
    "churn_rate = churned_customers / total_customers\n",
    "\n",
    "# ğŸ’° Business impact calculations\n",
    "avg_monthly_revenue = 75  # Average customer monthly value\n",
    "customer_acquisition_cost = 200  # Cost to acquire new customer\n",
    "\n",
    "monthly_revenue_lost = churned_customers * avg_monthly_revenue\n",
    "annual_revenue_lost = monthly_revenue_lost * 12\n",
    "replacement_cost = churned_customers * customer_acquisition_cost\n",
    "\n",
    "print('ğŸš¨ THE CHURN CRISIS REPORT')\n",
    "print('=' * 50)\n",
    "print(f'ğŸ“Š Total Customers: {total_customers:,}')\n",
    "print(f'âŒ Customers Lost: {churned_customers:,}')\n",
    "print(f'ğŸ“‰ Churn Rate: {churn_rate:.1%}')\n",
    "print(f'ğŸ’¸ Monthly Revenue Lost: ${monthly_revenue_lost:,}')\n",
    "print(f'ğŸ’¸ Annual Revenue Lost: ${annual_revenue_lost:,}')\n",
    "print(f'ğŸ’° Customer Replacement Cost: ${replacement_cost:,}')\n",
    "print(f'ğŸ”¥ Total Annual Impact: ${annual_revenue_lost + replacement_cost:,}')\n",
    "\n",
    "# ğŸ¯ Visualization: The Churn Story\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Churn distribution with dramatic colors\n",
    "churn_counts = df['Churn?'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']  # Green for retained, red for churned\n",
    "axes[0].pie(churn_counts.values, labels=['Retained ğŸ˜Š', 'Churned ğŸ˜'], \n",
    "           autopct='%1.1f%%', colors=colors, startangle=90, \n",
    "           explode=(0, 0.1))  # Explode the churn slice\n",
    "axes[0].set_title('ğŸ¯ Customer Retention vs Churn', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Revenue impact\n",
    "impact_data = ['Monthly Loss', 'Replacement Cost']\n",
    "impact_values = [monthly_revenue_lost/1000, replacement_cost/1000]  # In thousands\n",
    "bars = axes[1].bar(impact_data, impact_values, color=['#e74c3c', '#f39c12'])\n",
    "axes[1].set_title('ğŸ’° Financial Impact ($000s)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Cost ($000s)')\n",
    "for bar, value in zip(bars, impact_values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "                f'${value:.0f}K', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nğŸ¯ KEY INSIGHT: If we can reduce churn by just 25%, we could save ${(annual_revenue_lost + replacement_cost) * 0.25:,.0f} annually!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Chapter 2: Model Training - Teaching Machines to Predict\n",
    "\n",
    "Now let's train our models to identify at-risk customers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.349571Z",
     "start_time": "2025-08-17T17:39:37.339213Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ Data preprocessing\n",
    "print('ğŸ”§ PREPARING DATA FOR AI TRAINING')\n",
    "print('=' * 40)\n",
    "\n",
    "df_processed = df.copy()\n",
    "df_processed['Churn'] = (df_processed['Churn?'] == 'True.').astype(int)\n",
    "df_processed.drop('Churn?', axis=1, inplace=True)\n",
    "df_processed.drop('Phone', axis=1, inplace=True)  # Remove phone numbers\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['State', \"Int'l Plan\", 'VMail Plan']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# ğŸš€ Feature engineering: Create power features\n",
    "df_processed['Total_Charge'] = (df_processed['Day Charge'] + \n",
    "                               df_processed['Eve Charge'] + \n",
    "                               df_processed['Night Charge'] + \n",
    "                               df_processed['Intl Charge'])\n",
    "\n",
    "df_processed['Avg_Charge_Per_Min'] = df_processed['Total_Charge'] / (\n",
    "    df_processed['Day Mins'] + df_processed['Eve Mins'] + \n",
    "    df_processed['Night Mins'] + df_processed['Intl Mins'] + 1e-8)\n",
    "\n",
    "df_processed['High_Service_Calls'] = (df_processed['CustServ Calls'] >= 4).astype(int)\n",
    "\n",
    "print('âœ… Data preprocessing completed!')\n",
    "print(f'ğŸ“Š Final dataset: {df_processed.shape[0]:,} customers, {df_processed.shape[1]} features')\n",
    "print(f'ğŸ¯ Target distribution: {df_processed[\"Churn\"].mean():.1%} churn rate')\n",
    "\n",
    "# ğŸ¯ Prepare for model training\n",
    "X = df_processed.drop('Churn', axis=1)\n",
    "y = df_processed['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'ğŸ¯ Training set: {X_train.shape[0]:,} customers')\n",
    "print(f'ğŸ¯ Test set: {X_test.shape[0]:,} customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.803828Z",
     "start_time": "2025-08-17T17:39:37.368767Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ¤– MODEL BATTLE: Random Forest vs Logistic Regression\n",
    "print('ğŸ¤– AI MODEL TRAINING ARENA')\n",
    "print('=' * 50)\n",
    "\n",
    "models = {\n",
    "    'ğŸŒ² Random Forest': RandomForestClassifier(n_estimators=100, random_state=2),\n",
    "    'ğŸ“ˆ Logistic Regression': LogisticRegression(random_state=2, max_iter=1000)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\nğŸ¥Š Training {name}...')\n",
    "    \n",
    "    if 'Logistic' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'auc_score': auc_score\n",
    "    }\n",
    "    \n",
    "    print(f'   ğŸ¯ AUC Score: {auc_score:.4f}')\n",
    "    print(f'   ğŸ“Š Accuracy: {(y_pred == y_test).mean():.1%}')\n",
    "\n",
    "# ğŸ† Declare the winner\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['auc_score'])\n",
    "best_auc = model_results[best_model_name]['auc_score']\n",
    "\n",
    "print(f'\\nğŸ† WINNER: {best_model_name}')\n",
    "print(f'ğŸ¯ Champion AUC Score: {best_auc:.4f}')\n",
    "print(f'ğŸ’ª This means our AI can identify {best_auc:.1%} of potential churners correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Chapter 4: Action Plan - From Insights to Impact\n",
    "\n",
    "Specific, actionable strategies based on our model insights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.824277Z",
     "start_time": "2025-08-17T17:39:37.818579Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ ACTIONABLE BUSINESS RECOMMENDATIONS\n",
    "print('ğŸ¯ MODEL-POWERED BUSINESS ACTION PLAN')\n",
    "print('=' * 50)\n",
    "\n",
    "# Get feature importance\n",
    "rf_model = model_results['ğŸŒ² Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('ğŸ” TOP 5 CHURN DRIVERS:')\n",
    "for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "    print(f'  {i}. {row[\"feature\"]} (Impact: {row[\"importance\"]:.1%})')\n",
    "\n",
    "print('\\nğŸš€ DATA-DRIVEN RECOMMENDED ACTIONS:')\n",
    "print('ğŸŒ™ 1. NIGHT CHARGE OPTIMIZATION (Night Charge - Top Driver 14.4%):')\n",
    "print('   â€¢ Night charge alerts for customers exceeding thresholds')\n",
    "print('   â€¢ Bill shock prevention for night usage spikes')\n",
    "print('   â€¢ Night-focused retention plans')\n",
    "\n",
    "print('\\nâ˜€ï¸ 2. DAYTIME MINUTES MANAGEMENT (Day Mins - 13.6% Impact):')\n",
    "print('   â€¢ Daytime minute usage alerts for heavy users')\n",
    "print('   â€¢ Unlimited daytime calling plans for business customers')\n",
    "print('   â€¢ Proactive outreach for usage pattern changes')\n",
    "\n",
    "print('\\nğŸ“ 3. NIGHT CALL PATTERN ANALYSIS (Night Calls - 11.7% Impact):')\n",
    "print('   â€¢ Monitor night call frequency increases')\n",
    "print('   â€¢ Offer night-focused retention plans')\n",
    "print('   â€¢ Proactive outreach for night usage spikes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T17:39:37.856197Z",
     "start_time": "2025-08-17T17:39:37.839712Z"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ’¾ Save model for production\n",
    "import joblib\n",
    "\n",
    "print('ğŸ’¾ PREPARING MODEL FOR PRODUCTION')\n",
    "print('=' * 40)\n",
    "\n",
    "# Save model artifacts\n",
    "best_model = model_results[best_model_name]['model']\n",
    "joblib.dump(best_model, 'notebook_outputs/churn_prediction_model.pkl')\n",
    "joblib.dump(scaler, 'notebook_outputs/feature_scaler.pkl')\n",
    "joblib.dump(label_encoders, 'notebook_outputs/label_encoders.pkl')\n",
    "\n",
    "print('âœ… Model artifacts saved:')\n",
    "print('   ğŸ“ churn_prediction_model.pkl - Trained ML model')\n",
    "print('   ğŸ“ feature_scaler.pkl - Data preprocessing scaler')\n",
    "print('   ğŸ“ label_encoders.pkl - Categorical encoders')\n",
    "\n",
    "print('\\nğŸ¯ NEXT STEPS:')\n",
    "print('1. ğŸ—ï¸  Set up AWS SageMaker endpoint for real-time predictions')\n",
    "print('2. ğŸ”— Integrate with your CRM system for automated scoring')\n",
    "print('3. ğŸ“Š Create executive dashboard for monitoring churn metrics')\n",
    "print('4. ğŸ¯ Launch targeted retention campaigns for high-risk customers')\n",
    "print('5. ğŸ“ˆ A/B test different retention strategies')\n",
    "\n",
    "print('\\nğŸ‰ CONGRATULATIONS!')\n",
    "print('You now have a production-ready model system that can:')\n",
    "print(f'   ğŸ¯ Predict customer churn with {best_auc:.1%} accuracy')\n",
    "print('\\nğŸš€ Ready to transform your customer retention strategy!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
