"""End-to-end test for DataZone connections creation and CLI describe --connect."""

import pytest
import boto3
import time
import os
from typer.testing import CliRunner
from ..base import IntegrationTestBase
from smus_cicd.helpers.connection_creator import ConnectionCreator


class TestDataZoneConnectionsE2E(IntegrationTestBase):
    """Test DataZone connections integration with CLI."""

    def setup_method(self, method):
        """Set up test environment."""
        super().setup_method(method)
        self.setup_test_directory()
        self.created_connection_ids = []
        
        # Use region from environment or default
        region = os.environ.get('DEV_DOMAIN_REGION', 'us-east-2')
        self.datazone_client = boto3.client('datazone', region_name=region)
        
        # Find domain by tag
        domains = self.datazone_client.list_domains()
        self.domain_id = None
        for domain in domains.get('items', []):
            domain_detail = self.datazone_client.get_domain(identifier=domain['id'])
            tags = domain_detail.get('tags', {})
            if tags.get('purpose') == 'smus-cicd-testing':
                self.domain_id = domain['id']
                print(f"üîç Found test domain: {self.domain_id}")
                break
        
        if not self.domain_id:
            pytest.skip("No test domain found with tag purpose=smus-cicd-testing")
        
        # Find test project (prefer connections-test-project)
        projects = self.datazone_client.list_projects(
            domainIdentifier=self.domain_id,
            maxResults=50
        )
        self.project_id = None
        print(f"üîç Searching for connections-test-project in {len(projects.get('items', []))} projects")
        for project in projects.get('items', []):
            project_name = project.get('name', '')
            if project_name == 'connections-test-project':
                self.project_id = project['id']
                print(f"üîç Found test project: {project_name} ({self.project_id})")
                break
        
        if not self.project_id:
            print("‚ùå No connections-test-project found in domain")
            pytest.skip("No connections-test-project found in domain")
        
        # Get the first environment for this project
        try:
            env_response = self.datazone_client.list_environments(
                domainIdentifier=self.domain_id, projectIdentifier=self.project_id
            )
            environments = env_response.get("items", [])
            if environments:
                self.env_id = environments[0]["id"]
                print(f"üîç Using environment: {self.env_id}")
            else:
                pytest.skip("No environments found for project")
        except Exception as e:
            pytest.skip(f"Failed to get environment for project: {e}")
            
        # Initialize connection creator
        self.connection_creator = ConnectionCreator(self.domain_id, region)

    def teardown_method(self, method):
        """Clean up test environment."""
        # Only cleanup connections created by test_datazone_connections_end_to_end
        # Leave bootstrap connections for inspection
        if method.__name__ == 'test_datazone_connections_end_to_end':
            for conn_id in self.created_connection_ids:
                try:
                    self.datazone_client.delete_connection(
                        domainIdentifier=self.domain_id,
                        identifier=conn_id
                    )
                    print(f"‚úÖ Cleaned up connection: {conn_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Failed to cleanup connection {conn_id}: {e}")
        
        super().teardown_method(method)
        self.cleanup_test_directory()

    def create_test_connections(self):
        """Create test connections using the helper method."""
        timestamp = int(time.time())
        
        # Define all 8 supported connection types with their configurations
        connection_configs = [
            {
                'name': f'test-s3-{timestamp}',
                'type': 'S3',
                'kwargs': {'s3_uri': 's3://test-datazone-connections-bucket/data/'}
            },
            {
                'name': f'test-iam-{timestamp}',
                'type': 'IAM',
                'kwargs': {'glue_lineage_sync': True}
            },
            {
                'name': f'test-spark-glue-{timestamp}',
                'type': 'SPARK_GLUE',
                'kwargs': {
                    'glue_version': '4.0',
                    'worker_type': 'G.1X',
                    'num_workers': 3
                }
            },
            {
                'name': f'test-athena-{timestamp}',
                'type': 'ATHENA',
                'kwargs': {
                    'workgroup': 'workgroup-buxme33txzr413-dtadp6zmf87b53'
                }
            },
            {
                'name': f'test-redshift-{timestamp}',
                'type': 'REDSHIFT',
                'kwargs': {
                    'cluster_name': 'test-analytics-cluster',
                    'database_name': 'analytics',
                    'host': 'test-analytics-cluster.abc123.us-east-1.redshift.amazonaws.com',
                    'port': 5439
                }
            },
            {
                'name': f'test-spark-emr-{timestamp}',
                'type': 'SPARK_EMR',
                'kwargs': {
                    'compute_arn': 'arn:aws:emr-serverless:us-east-1:123456789012:/applications/00abc123def456',
                    'runtime_role': 'arn:aws:iam::123456789012:role/EMRServerlessExecutionRole'
                }
            },
            {
                'name': f'test-mlflow-{timestamp}',
                'type': 'MLFLOW',
                'kwargs': {
                    'tracking_server_arn': 'arn:aws:sagemaker:${STS_REGION}:${STS_ACCOUNT_ID}:mlflow-tracking-server/smus-integration-mlflow-use2'
                }
            },
            {
                'name': f'test-mwaa-{timestamp}',
                'type': 'WORKFLOWS_MWAA',
                'kwargs': {
                    'mwaa_environment_name': 'DataZoneMWAAEnv-dzd_6je2k8b63qse07-4kc6456xevd0h3-dev'
                }
            },
            {
                'name': f'test-serverless-{timestamp}',
                'type': 'WORKFLOWS_SERVERLESS',
                'kwargs': {}
            }
        ]
        
        created_connections = []
        
        # Resolve pseudo env vars for test
        import boto3
        session = boto3.Session()
        sts_region = session.region_name
        sts_account_id = session.client("sts").get_caller_identity()["Account"]
        
        for config in connection_configs:
            try:
                # Substitute STS pseudo env vars in kwargs
                kwargs = {}
                for key, value in config['kwargs'].items():
                    if isinstance(value, str):
                        value = value.replace('${STS_REGION}', sts_region)
                        value = value.replace('${STS_ACCOUNT_ID}', sts_account_id)
                    kwargs[key] = value
                
                connection_id = self.connection_creator.create_connection(
                    environment_id=self.env_id,
                    name=config['name'],
                    connection_type=config['type'],
                    description=f"Test {config['type']} connection for E2E testing",
                    **kwargs
                )
                
                self.created_connection_ids.append(connection_id)
                created_connections.append({
                    'id': connection_id,
                    'name': config['name'],
                    'type': config['type']
                })
                print(f"‚úÖ Created {config['type']} connection: {config['name']} ({connection_id})")
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Skipping {config['type']} connection due to creation failure: {e}")
        
        return created_connections

    def test_datazone_connections_end_to_end(self):
        """Test end-to-end DataZone connections integration with CLI."""
        print("\n=== DataZone Connections End-to-End Test ===")
        
        # Step 1: Create connections using helper
        print(f"\nStep 1: Creating connections in DataZone using helper...")
        created_connections = self.create_test_connections()
        
        if len(created_connections) == 0:
            pytest.fail("Failed to create any connections")
        
        print(f"‚úÖ Successfully created {len(created_connections)} connections in DataZone")
        print(f"\nConnection types created:")
        for conn in created_connections:
            print(f"  - {conn['type']}: {conn['name']}")
        
        # Step 2: Verify connections exist using get_connection API
        print(f"\nStep 2: Verifying connections exist using get_connection API...")
        verified_connections = 0
        for conn in created_connections:
            try:
                get_response = self.datazone_client.get_connection(
                    domainIdentifier=self.domain_id,
                    identifier=conn["id"]
                )
                
                actual_type = get_response.get("type", "UNKNOWN")
                expected_type = conn["type"]
                
                # Handle type normalization (SPARK_GLUE -> SPARK)
                if expected_type == "SPARK_GLUE" and actual_type == "SPARK":
                    actual_type = expected_type
                
                # Validate MLflow ARN is resolved (no wildcards)
                if expected_type == "MLFLOW":
                    props = get_response.get("props", {})
                    mlflow_props = props.get("mlflowProperties", {})
                    tracking_arn = mlflow_props.get("trackingServerArn", "")
                    
                    print(f"  üîç MLflow ARN: {tracking_arn}")
                    
                    # Assert no wildcards in ARN
                    assert "*" not in tracking_arn, f"MLflow ARN still contains wildcards: {tracking_arn}"
                    
                    # Assert ARN contains actual region and account
                    import boto3
                    session = boto3.Session()
                    current_region = session.region_name
                    current_account = session.client("sts").get_caller_identity()["Account"]
                    
                    assert current_region in tracking_arn, f"MLflow ARN missing region {current_region}: {tracking_arn}"
                    assert current_account in tracking_arn, f"MLflow ARN missing account {current_account}: {tracking_arn}"
                    
                    print(f"  ‚úÖ MLflow ARN fully resolved: region={current_region}, account={current_account}")
                
                print(f"  ‚úÖ Verified connection: {conn['name']} ({expected_type} ‚Üí {actual_type}) - {conn['id']}")
                verified_connections += 1
                
            except Exception as e:
                print(f"  ‚ùå Failed to verify connection {conn['name']}: {e}")
                raise
        
        print(f"‚úÖ All {verified_connections} connections verified via get_connection API")
        
        # Step 3: Test CLI describe --connect
        print(f"\nStep 3: Testing CLI describe --connect...")
        
        # Debug: Check how many connections exist right now
        check_response = self.datazone_client.list_connections(
            domainIdentifier=self.domain_id,
            projectIdentifier=self.project_id,
            maxResults=50
        )
        print(f"üîç DEBUG: DataZone API shows {len(check_response.get('items', []))} connections before describe")
        
        # Get region from client
        region = self.datazone_client.meta.region_name
        
        # Get actual project name
        project_detail = self.datazone_client.get_project(
            domainIdentifier=self.domain_id,
            identifier=self.project_id
        )
        project_name = project_detail.get('name')
        
        # Create test manifest with purpose tag to find domain and actual project name
        test_manifest_content = f"""applicationName: TestConnectionsE2E

stages:
  test:
    stage: TEST 
    domain:
      tags:
        purpose: smus-cicd-testing
      region: {region}
    project: 
      name: {project_name}
"""
        
        test_manifest_path = self.test_dir + "/test_manifest.yaml"
        with open(test_manifest_path, 'w') as f:
            f.write(test_manifest_content)
        
        # Execute CLI command
        result = self.run_cli_command([
            "describe", "--manifest", test_manifest_path, "--connect"
        ])
        
        if result["success"]:
            print("‚úÖ CLI describe --connect command successful")
            cli_output = result["output"]
            print("CLI OUTPUT:")
            print(cli_output)
            
            # Step 4: Validate connections appear in CLI output
            print(f"\nStep 4: Validating connections appear in CLI output...")
            connections_found_in_cli = 0
            
            for conn in created_connections:
                if conn["name"] in cli_output:
                    connections_found_in_cli += 1
                    print(f"  ‚úÖ Found connection in CLI: {conn['name']} ({conn['type']})")
                else:
                    print(f"  ‚ùå Missing connection in CLI: {conn['name']} ({conn['type']})")
            
            # Success criteria: At least 25% of connections should be visible in CLI
            # (Main goal is to verify wildcard resolution works, not full CLI integration)
            success_threshold = max(1, len(created_connections) // 4)
            
            assert connections_found_in_cli >= success_threshold, \
                f"Expected at least {success_threshold} connections in CLI output, found {connections_found_in_cli}. " \
                f"CLI integration partially working - {connections_found_in_cli}/{len(created_connections)} connections visible."

            print(f"‚úÖ CLI integration test passed: {connections_found_in_cli}/{len(created_connections)} connections visible in CLI output")
            
        else:
            pytest.fail(f"CLI describe --connect command failed: {result.get('output', 'Unknown error')}")

        print(f"\nüéâ End-to-End test completed successfully!")
        print(f"   - Created {len(created_connections)} connections in DataZone")
        print(f"   - Connection types: {', '.join(sorted(set(c['type'] for c in created_connections)))}")
        print(f"   - Confirmed CLI describe --connect shows {connections_found_in_cli} connections")

    def test_bootstrap_connection_idempotency(self):
        """Test that bootstrap connections are idempotent on re-deploy, especially MLflow."""
        print("\n=== Bootstrap Connection Idempotency Test ===")
        
        if not self.verify_aws_connectivity():
            pytest.skip("AWS connectivity not available")
        
        manifest_path = os.path.join(os.path.dirname(__file__), "manifest.yaml")
        
        # Cleanup: Delete existing test connections before starting
        print("\nCleanup: Removing existing test connections...")
        test_connection_names = [
            's3-data-lake', 'iam-lineage', 'spark-glue-proc',
            'workflows-serverless', 'mlflow-experiments'
        ]
        
        try:
            connections = self.datazone_client.list_connections(
                domainIdentifier=self.domain_id,
                projectIdentifier=self.project_id,
                maxResults=50
            )
            for conn in connections.get('items', []):
                if conn.get('name') in test_connection_names:
                    try:
                        self.datazone_client.delete_connection(
                            domainIdentifier=self.domain_id,
                            identifier=conn.get('connectionId')  # Use connectionId
                        )
                        print(f"  ‚úÖ Deleted: {conn.get('name')}")
                    except Exception as e:
                        print(f"  ‚ö†Ô∏è  Failed to delete {conn.get('name')}: {e}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Failed to list connections: {e}")
        
        # Step 1: First deployment - creates connections
        print("\nStep 1: First deployment (creates connections)...")
        result1 = self.run_cli_command([
            "deploy", "--manifest", manifest_path, "--targets", "test"
        ])
        
        assert result1["success"], f"First deployment failed: {result1['output']}"
        print("‚úÖ First deployment successful")
        
        # Wait for connections to be fully created
        time.sleep(2)
        
        # Verify MLflow connection was created
        connections = self.datazone_client.list_connections(
            domainIdentifier=self.domain_id,
            projectIdentifier=self.project_id,
            maxResults=50
        )
        mlflow_conn = None
        for conn in connections.get('items', []):
            if conn.get('name') == 'mlflow-experiments':
                mlflow_conn = conn
                break
        
        assert mlflow_conn is not None, "MLflow connection not found after first deployment"
        mlflow_conn_id = mlflow_conn.get('connectionId')
        assert mlflow_conn_id, "MLflow connection has no connectionId"
        print(f"‚úÖ MLflow connection created: {mlflow_conn_id}")
        
        # Step 2: Second deployment - should be idempotent
        print("\nStep 2: Second deployment (should be idempotent)...")
        result2 = self.run_cli_command([
            "deploy", "--manifest", manifest_path, "--targets", "test"
        ])
        
        # This is the critical test - should NOT fail with update error
        assert result2["success"], f"Second deployment failed (not idempotent): {result2['output']}"
        
        # Verify no update errors in output
        assert "Failed to update connection" not in result2["output"], \
            "Should not attempt to update MLflow connection"
        assert "Parameter validation failed" not in result2["output"], \
            "Should not have parameter validation errors"
        # Note: mlflowProperties may appear in debug logs, which is OK
        
        print("‚úÖ Second deployment successful (idempotent)")
        
        # Step 3: Verify MLflow connection unchanged
        print("\nStep 3: Verifying MLflow connection unchanged...")
        mlflow_conn_after = self.datazone_client.get_connection(
            domainIdentifier=self.domain_id,
            identifier=mlflow_conn_id
        )
        
        assert mlflow_conn_after['connectionId'] == mlflow_conn_id, "MLflow connection ID changed"
        print(f"‚úÖ MLflow connection unchanged: {mlflow_conn_id}")
        
        # Step 4: Verify connection is skipped with proper message
        print("\nStep 4: Verifying skip message in output...")
        if "MLflow connection" in result2["output"] and "already exists" in result2["output"]:
            print("‚úÖ Found skip message for MLflow connection")
        elif "mlflow-experiments" in result2["output"] and "exists" in result2["output"]:
            print("‚úÖ Found skip message for mlflow-experiments")
        else:
            print("‚ö†Ô∏è  No explicit skip message found, but deployment succeeded")
        
        print("\nüéâ Bootstrap idempotency test completed successfully!")
        print("   - First deployment: created connections")
        print("   - Second deployment: idempotent (no errors)")
        print("   - MLflow connection: immutable (not updated)")

    def test_mlflow_connection_property_change_recreates(self):
        """Test that MLflow connection is deleted and recreated when properties change."""
        print("\n=== MLflow Connection Property Change Test ===")
        
        if not self.verify_aws_connectivity():
            pytest.skip("AWS connectivity not available")
        
        # Create temporary manifest with initial MLflow ARN
        manifest_content = f"""applicationName: ConnectionsTestBundle
content:
  storage:
  - name: src
    connectionName: default.s3_shared
    include:
    - src
    exclude:
    - .ipynb_checkpoints/
    - __pycache__/
    - '*.pyc'
    - .libs.json
stages:
  test:
    stage: TEST
    domain:
      tags:
        purpose: smus-cicd-testing
      region: us-east-2
    project:
      name: connections-test-project
      create: true
      profile_name: All capabilities
      owners:
      - Eng1
      - arn:aws:iam::198737698272:role/Admin
      contributors: []
    deployment_configuration:
      storage:
      - name: src
        connectionName: default.s3_shared
        targetDirectory: connections-test/src
    bootstrap:
      actions:
      - type: datazone.create_environment
        environment_configuration_name: OnDemand Workflows
      - type: datazone.create_connection
        name: mlflow-test-change
        connection_type: MLFLOW
        properties:
          trackingServerArn: arn:aws:sagemaker:us-east-1:198737698272:mlflow-tracking-server/original-server
"""
        
        manifest_path = os.path.join(self.test_dir, "manifest_mlflow_change.yaml")
        with open(manifest_path, 'w') as f:
            f.write(manifest_content)
        
        # Cleanup: Delete if exists
        print("\nCleanup: Removing mlflow-test-change if exists...")
        try:
            connections = self.datazone_client.list_connections(
                domainIdentifier=self.domain_id,
                projectIdentifier=self.project_id,
                maxResults=50
            )
            for conn in connections.get('items', []):
                if conn.get('name') == 'mlflow-test-change':
                    self.datazone_client.delete_connection(
                        domainIdentifier=self.domain_id,
                        identifier=conn.get('connectionId')
                    )
                    print("  ‚úÖ Deleted existing mlflow-test-change")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Cleanup failed: {e}")
        
        # Step 1: Create MLflow connection with original ARN
        print("\nStep 1: Creating MLflow connection with original ARN...")
        result1 = self.run_cli_command([
            "deploy", "--manifest", manifest_path, "--targets", "test"
        ])
        assert result1["success"], f"First deployment failed: {result1['output']}"
        
        # Wait for connection to be fully created
        time.sleep(2)
        
        # Get original connection ID
        connections = self.datazone_client.list_connections(
            domainIdentifier=self.domain_id,
            projectIdentifier=self.project_id,
            maxResults=50
        )
        original_conn = None
        for conn in connections.get('items', []):
            if conn.get('name') == 'mlflow-test-change':
                original_conn = conn
                break
        
        assert original_conn, "MLflow connection not created"
        original_id = original_conn.get('connectionId')
        original_arn = original_conn.get('props', {}).get('mlflowProperties', {}).get('trackingServerArn')
        print(f"‚úÖ Original connection: {original_id}, ARN: {original_arn}")
        
        # Step 2: Update manifest with different ARN
        print("\nStep 2: Updating manifest with different ARN...")
        manifest_content_updated = manifest_content.replace(
            'original-server',
            'updated-server'
        )
        with open(manifest_path, 'w') as f:
            f.write(manifest_content_updated)
        
        # Step 3: Deploy with changed ARN - should delete and recreate
        print("\nStep 3: Deploying with changed ARN (should delete+recreate)...")
        result2 = self.run_cli_command([
            "deploy", "--manifest", manifest_path, "--targets", "test"
        ])
        assert result2["success"], f"Second deployment failed: {result2['output']}"
        
        # Wait for connection to be recreated
        time.sleep(2)
        
        # Step 4: Verify connection was recreated with new ID and ARN
        print("\nStep 4: Verifying connection was recreated...")
        connections_after = self.datazone_client.list_connections(
            domainIdentifier=self.domain_id,
            projectIdentifier=self.project_id,
            maxResults=50
        )
        new_conn = None
        for conn in connections_after.get('items', []):
            if conn.get('name') == 'mlflow-test-change':
                new_conn = conn
                break
        
        assert new_conn, "MLflow connection not found after update"
        new_id = new_conn.get('connectionId')
        new_arn = new_conn.get('props', {}).get('mlflowProperties', {}).get('trackingServerArn')
        
        print(f"‚úÖ New connection: {new_id}, ARN: {new_arn}")
        
        # Verify ID changed (recreated)
        assert new_id != original_id, f"Connection ID should change (delete+recreate), but stayed {original_id}"
        
        # Verify ARN updated
        assert 'updated-server' in new_arn, f"ARN should contain 'updated-server', got: {new_arn}"
        assert 'original-server' not in new_arn, f"ARN should not contain 'original-server', got: {new_arn}"
        
        print("\nüéâ MLflow property change test completed successfully!")
        print(f"   - Original: {original_id} ‚Üí {original_arn}")
        print(f"   - Updated:  {new_id} ‚Üí {new_arn}")
        print("   - Connection was deleted and recreated (ID changed)")
