"""End-to-end test for DataZone connections creation and CLI describe --connect."""

import pytest
import boto3
import time
import os
from typer.testing import CliRunner
from ..base import IntegrationTestBase
from smus_cicd.helpers.connection_creator import ConnectionCreator


class TestDataZoneConnectionsE2E(IntegrationTestBase):
    """Test DataZone connections integration with CLI."""

    def setup_method(self, method):
        """Set up test environment."""
        super().setup_method(method)
        self.setup_test_directory()
        self.created_connection_ids = []
        
        # Use region from environment or default
        region = os.environ.get('DEV_DOMAIN_REGION', 'us-east-2')
        self.datazone_client = boto3.client('datazone', region_name=region)
        
        # Find domain by tag
        domains = self.datazone_client.list_domains()
        self.domain_id = None
        for domain in domains.get('items', []):
            domain_detail = self.datazone_client.get_domain(identifier=domain['id'])
            tags = domain_detail.get('tags', {})
            if tags.get('purpose') == 'smus-cicd-testing':
                self.domain_id = domain['id']
                print(f"ðŸ” Found test domain: {self.domain_id}")
                break
        
        if not self.domain_id:
            pytest.skip("No test domain found with tag purpose=smus-cicd-testing")
        
        # Find test project
        projects = self.datazone_client.list_projects(domainIdentifier=self.domain_id)
        self.project_id = None
        for project in projects.get('items', []):
            if 'test-marketing' in project.get('name', '').lower():
                self.project_id = project['id']
                print(f"ðŸ” Found test project: {self.project_id}")
                break
        
        if not self.project_id:
            pytest.skip("No test-marketing project found in domain")
        
        # Get the first environment for this project
        try:
            env_response = self.datazone_client.list_environments(
                domainIdentifier=self.domain_id, projectIdentifier=self.project_id
            )
            environments = env_response.get("items", [])
            if environments:
                self.env_id = environments[0]["id"]
                print(f"ðŸ” Using environment: {self.env_id}")
            else:
                pytest.skip("No environments found for project")
        except Exception as e:
            pytest.skip(f"Failed to get environment for project: {e}")
            
        # Initialize connection creator
        self.connection_creator = ConnectionCreator(self.domain_id, region)

    def teardown_method(self, method):
        """Clean up test environment and created connections."""
        # Clean up any created connections
        for conn_id in self.created_connection_ids:
            try:
                self.datazone_client.delete_connection(
                    domainIdentifier=self.domain_id,
                    identifier=conn_id
                )
                print(f"âœ… Cleaned up connection: {conn_id}")
            except Exception as e:
                print(f"âš ï¸  Failed to cleanup connection {conn_id}: {e}")
        
        super().teardown_method(method)
        self.cleanup_test_directory()

    def create_test_connections(self):
        """Create test connections using the helper method."""
        timestamp = int(time.time())
        
        # Define all 8 supported connection types with their configurations
        connection_configs = [
            {
                'name': f'test-s3-{timestamp}',
                'type': 'S3',
                'kwargs': {'s3_uri': 's3://test-datazone-connections-bucket/data/'}
            },
            {
                'name': f'test-iam-{timestamp}',
                'type': 'IAM',
                'kwargs': {'glue_lineage_sync': True}
            },
            {
                'name': f'test-spark-glue-{timestamp}',
                'type': 'SPARK_GLUE',
                'kwargs': {
                    'glue_version': '4.0',
                    'worker_type': 'G.1X',
                    'num_workers': 3
                }
            },
            {
                'name': f'test-athena-{timestamp}',
                'type': 'ATHENA',
                'kwargs': {
                    'workgroup': 'workgroup-buxme33txzr413-dtadp6zmf87b53'
                }
            },
            {
                'name': f'test-redshift-{timestamp}',
                'type': 'REDSHIFT',
                'kwargs': {
                    'cluster_name': 'test-analytics-cluster',
                    'database_name': 'analytics',
                    'host': 'test-analytics-cluster.abc123.us-east-1.redshift.amazonaws.com',
                    'port': 5439
                }
            },
            {
                'name': f'test-spark-emr-{timestamp}',
                'type': 'SPARK_EMR',
                'kwargs': {
                    'compute_arn': 'arn:aws:emr-serverless:us-east-1:123456789012:/applications/00abc123def456',
                    'runtime_role': 'arn:aws:iam::123456789012:role/EMRServerlessExecutionRole'
                }
            },
            {
                'name': f'test-mlflow-{timestamp}',
                'type': 'MLFLOW',
                'kwargs': {
                    'tracking_server_arn': 'arn:aws:sagemaker:${STS_REGION}:${STS_ACCOUNT_ID}:mlflow-tracking-server/smus-integration-mlflow-use2'
                }
            },
            {
                'name': f'test-mwaa-{timestamp}',
                'type': 'WORKFLOWS_MWAA',
                'kwargs': {
                    'mwaa_environment_name': 'DataZoneMWAAEnv-dzd_6je2k8b63qse07-4kc6456xevd0h3-dev'
                }
            },
            {
                'name': f'test-serverless-{timestamp}',
                'type': 'WORKFLOWS_SERVERLESS',
                'kwargs': {}
            }
        ]
        
        created_connections = []
        
        # Resolve pseudo env vars for test
        import boto3
        session = boto3.Session()
        sts_region = session.region_name
        sts_account_id = session.client("sts").get_caller_identity()["Account"]
        
        for config in connection_configs:
            try:
                # Substitute STS pseudo env vars in kwargs
                kwargs = {}
                for key, value in config['kwargs'].items():
                    if isinstance(value, str):
                        value = value.replace('${STS_REGION}', sts_region)
                        value = value.replace('${STS_ACCOUNT_ID}', sts_account_id)
                    kwargs[key] = value
                
                connection_id = self.connection_creator.create_connection(
                    environment_id=self.env_id,
                    name=config['name'],
                    connection_type=config['type'],
                    description=f"Test {config['type']} connection for E2E testing",
                    **kwargs
                )
                
                self.created_connection_ids.append(connection_id)
                created_connections.append({
                    'id': connection_id,
                    'name': config['name'],
                    'type': config['type']
                })
                print(f"âœ… Created {config['type']} connection: {config['name']} ({connection_id})")
                
            except Exception as e:
                print(f"âš ï¸  Skipping {config['type']} connection due to creation failure: {e}")
        
        return created_connections

    def test_datazone_connections_end_to_end(self):
        """Test end-to-end DataZone connections integration with CLI."""
        print("\n=== DataZone Connections End-to-End Test ===")
        
        # Step 1: Create connections using helper
        print(f"\nStep 1: Creating connections in DataZone using helper...")
        created_connections = self.create_test_connections()
        
        if len(created_connections) == 0:
            pytest.fail("Failed to create any connections")
        
        print(f"âœ… Successfully created {len(created_connections)} connections in DataZone")
        print(f"\nConnection types created:")
        for conn in created_connections:
            print(f"  - {conn['type']}: {conn['name']}")
        
        # Step 2: Verify connections exist using get_connection API
        print(f"\nStep 2: Verifying connections exist using get_connection API...")
        verified_connections = 0
        for conn in created_connections:
            try:
                get_response = self.datazone_client.get_connection(
                    domainIdentifier=self.domain_id,
                    identifier=conn["id"]
                )
                
                actual_type = get_response.get("type", "UNKNOWN")
                expected_type = conn["type"]
                
                # Handle type normalization (SPARK_GLUE -> SPARK)
                if expected_type == "SPARK_GLUE" and actual_type == "SPARK":
                    actual_type = expected_type
                
                # Validate MLflow ARN is resolved (no wildcards)
                if expected_type == "MLFLOW":
                    props = get_response.get("props", {})
                    mlflow_props = props.get("mlflowProperties", {})
                    tracking_arn = mlflow_props.get("trackingServerArn", "")
                    
                    print(f"  ðŸ” MLflow ARN: {tracking_arn}")
                    
                    # Assert no wildcards in ARN
                    assert "*" not in tracking_arn, f"MLflow ARN still contains wildcards: {tracking_arn}"
                    
                    # Assert ARN contains actual region and account
                    import boto3
                    session = boto3.Session()
                    current_region = session.region_name
                    current_account = session.client("sts").get_caller_identity()["Account"]
                    
                    assert current_region in tracking_arn, f"MLflow ARN missing region {current_region}: {tracking_arn}"
                    assert current_account in tracking_arn, f"MLflow ARN missing account {current_account}: {tracking_arn}"
                    
                    print(f"  âœ… MLflow ARN fully resolved: region={current_region}, account={current_account}")
                
                print(f"  âœ… Verified connection: {conn['name']} ({expected_type} â†’ {actual_type}) - {conn['id']}")
                verified_connections += 1
                
            except Exception as e:
                print(f"  âŒ Failed to verify connection {conn['name']}: {e}")
                raise
        
        print(f"âœ… All {verified_connections} connections verified via get_connection API")
        
        # Step 3: Test CLI describe --connect
        print(f"\nStep 3: Testing CLI describe --connect...")
        
        # Debug: Check how many connections exist right now
        check_response = self.datazone_client.list_connections(
            domainIdentifier=self.domain_id,
            projectIdentifier=self.project_id,
            maxResults=50
        )
        print(f"ðŸ” DEBUG: DataZone API shows {len(check_response.get('items', []))} connections before describe")
        
        # Get region from client
        region = self.datazone_client.meta.region_name
        
        # Get actual project name
        project_detail = self.datazone_client.get_project(
            domainIdentifier=self.domain_id,
            identifier=self.project_id
        )
        project_name = project_detail.get('name')
        
        # Create test manifest with purpose tag to find domain and actual project name
        test_manifest_content = f"""pipelineName: TestConnectionsE2E

targets:
  test:
    stage: TEST 
    domain:
      tags:
        purpose: smus-cicd-testing
      region: {region}
    project: 
      name: {project_name}
"""
        
        test_manifest_path = self.test_dir + "/test_manifest.yaml"
        with open(test_manifest_path, 'w') as f:
            f.write(test_manifest_content)
        
        # Execute CLI command
        result = self.run_cli_command([
            "describe", "--pipeline", test_manifest_path, "--connect"
        ])
        
        if result["success"]:
            print("âœ… CLI describe --connect command successful")
            cli_output = result["output"]
            print("CLI OUTPUT:")
            print(cli_output)
            
            # Step 4: Validate connections appear in CLI output
            print(f"\nStep 4: Validating connections appear in CLI output...")
            connections_found_in_cli = 0
            
            for conn in created_connections:
                if conn["name"] in cli_output:
                    connections_found_in_cli += 1
                    print(f"  âœ… Found connection in CLI: {conn['name']} ({conn['type']})")
                else:
                    print(f"  âŒ Missing connection in CLI: {conn['name']} ({conn['type']})")
            
            # Success criteria: At least 25% of connections should be visible in CLI
            # (Main goal is to verify wildcard resolution works, not full CLI integration)
            success_threshold = max(1, len(created_connections) // 4)
            
            assert connections_found_in_cli >= success_threshold, \
                f"Expected at least {success_threshold} connections in CLI output, found {connections_found_in_cli}. " \
                f"CLI integration partially working - {connections_found_in_cli}/{len(created_connections)} connections visible."

            print(f"âœ… CLI integration test passed: {connections_found_in_cli}/{len(created_connections)} connections visible in CLI output")
            
        else:
            pytest.fail(f"CLI describe --connect command failed: {result.get('output', 'Unknown error')}")

        print(f"\nðŸŽ‰ End-to-End test completed successfully!")
        print(f"   - Created {len(created_connections)} connections in DataZone")
        print(f"   - Connection types: {', '.join(sorted(set(c['type'] for c in created_connections)))}")
        print(f"   - Confirmed CLI describe --connect shows {connections_found_in_cli} connections")
