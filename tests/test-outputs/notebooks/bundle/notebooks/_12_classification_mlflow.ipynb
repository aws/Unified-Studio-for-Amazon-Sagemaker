{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74362827",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf9a219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:06:08.201435Z",
     "iopub.status.busy": "2025-11-10T22:06:08.201173Z",
     "iopub.status.idle": "2025-11-10T22:06:08.205973Z",
     "shell.execute_reply": "2025-11-10T22:06:08.204670Z"
    },
    "papermill": {
     "duration": 0.010406,
     "end_time": "2025-11-10T22:06:08.206779",
     "exception": false,
     "start_time": "2025-11-10T22:06:08.196373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Start Time: 2025-11-10 22:06:08\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f\"Execution Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586c038d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:06:08.215104Z",
     "iopub.status.busy": "2025-11-10T22:06:08.214873Z",
     "iopub.status.idle": "2025-11-10T22:06:08.218246Z",
     "shell.execute_reply": "2025-11-10T22:06:08.217380Z"
    },
    "papermill": {
     "duration": 0.008757,
     "end_time": "2025-11-10T22:06:08.219065",
     "exception": false,
     "start_time": "2025-11-10T22:06:08.210308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default sagemaker_studio package from environment\n"
     ]
    }
   ],
   "source": [
    "# Package upgrade skipped - using environment default\n",
    "print('Using default sagemaker_studio package from environment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a63306",
   "metadata": {
    "papermill": {
     "duration": 0.002992,
     "end_time": "2025-11-10T22:06:08.225462",
     "exception": false,
     "start_time": "2025-11-10T22:06:08.222470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test 12: Classification Example using MLFlow\n",
    "\n",
    "This notebook is used to illustated and end to end classification example using SageMaker MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d431fc",
   "metadata": {
    "papermill": {
     "duration": 0.003604,
     "end_time": "2025-11-10T22:06:08.231999",
     "exception": false,
     "start_time": "2025-11-10T22:06:08.228395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Goals**\n",
    "- Load and explore data\n",
    "- Feature engineering & preprocessing\n",
    "- Train baseline model(s)\n",
    "- Run hyperparameter tuning\n",
    "- Log experiments, metrics, params, artifacts, and models to MLflow\n",
    "- Visualize results (confusion matrix, ROC, PR, feature importance)\n",
    "- Load a model from MLflow and run inference\n",
    "\n",
    "**Requirements**\n",
    "- Packages: `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `mlflow`, `joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ed7a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:06:08.239961Z",
     "iopub.status.busy": "2025-11-10T22:06:08.239693Z",
     "iopub.status.idle": "2025-11-10T22:06:11.170027Z",
     "shell.execute_reply": "2025-11-10T22:06:11.168882Z"
    },
    "papermill": {
     "duration": 2.936069,
     "end_time": "2025-11-10T22:06:11.171040",
     "exception": false,
     "start_time": "2025-11-10T22:06:08.234971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d6115",
   "metadata": {
    "papermill": {
     "duration": 0.003183,
     "end_time": "2025-11-10T22:06:11.178112",
     "exception": false,
     "start_time": "2025-11-10T22:06:11.174929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configure MLflow tracking\n",
    "We will be using the MLFlow tracking server that is available as a connection in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2423a91",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a79f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:06:11.186329Z",
     "iopub.status.busy": "2025-11-10T22:06:11.185867Z",
     "iopub.status.idle": "2025-11-10T22:06:14.161833Z",
     "shell.execute_reply": "2025-11-10T22:06:14.160851Z"
    },
    "papermill": {
     "duration": 2.981725,
     "end_time": "2025-11-10T22:06:14.163094",
     "exception": true,
     "start_time": "2025-11-10T22:06:11.181369",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Field name duplicated: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker_studio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Project\n\u001b[1;32m      2\u001b[0m project \u001b[38;5;241m=\u001b[39m Project()\n\u001b[0;32m----> 3\u001b[0m tracking_server_uri \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlflow-server\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mtracking_server_arn\n\u001b[1;32m      4\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(tracking_server_uri)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow tracking URI:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mlflow\u001b[38;5;241m.\u001b[39mget_tracking_uri())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker_studio/connections/connection.py:233\u001b[0m, in \u001b[0;36mConnection.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Retrieves all the detailed connection data as a ConnectionData object.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m        ConnectionData: The connection data.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connection_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker_studio/connections/connection.py:508\u001b[0m, in \u001b[0;36mConnection._create_connection_data\u001b[0;34m(self, connection_data)\u001b[0m\n\u001b[1;32m    506\u001b[0m         connection_data_snake_case[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_camel_to_snake(key)] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    507\u001b[0m connection_data_class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnectionData\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 508\u001b[0m connection_data_class \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_data_class_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcustom_repr_for_credentials_password\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m     data_dict \u001b[38;5;241m=\u001b[39m asdict(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/dataclasses.py:1433\u001b[0m, in \u001b[0;36mmake_dataclass\u001b[0;34m(cls_name, fields, bases, namespace, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField names must not be keywords: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m seen:\n\u001b[0;32m-> 1433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField name duplicated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1435\u001b[0m seen\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m   1436\u001b[0m annotations[name] \u001b[38;5;241m=\u001b[39m tp\n",
      "\u001b[0;31mTypeError\u001b[0m: Field name duplicated: 'name'"
     ]
    }
   ],
   "source": [
    "from sagemaker_studio import Project\n",
    "project = Project()\n",
    "tracking_server_uri = project.connection('mlflow-server').data.tracking_server_arn\n",
    "mlflow.set_tracking_uri(tracking_server_uri)\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b1735",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Load dataset and quick EDA\n",
    "We'll use scikit-learn's breast cancer dataset (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f39c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bc = load_breast_cancer(as_frame=True)\n",
    "X = bc.frame.drop(columns=[\"target\"])\n",
    "y = bc.frame[\"target\"]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba087246",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Quick visual checks\n",
    "- Pairwise plots or feature distributions\n",
    "- Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50cd20",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4 — Correlation heatmap + a few distributions\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr = X.corr()\n",
    "sns.heatmap(corr, cmap=\"vlag\", center=0)\n",
    "plt.title(\"Feature correlation matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show distributions of a few representative features\n",
    "sample_features = feature_names[:6]\n",
    "X[sample_features].hist(figsize=(12, 6), bins=20)\n",
    "plt.suptitle(\"Sample feature distributions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72940b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train / test split\n",
    "Use stratified split to keep class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54d5e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5 — Train-test split\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f87bb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Baseline: Logistic Regression pipeline\n",
    "We'll create a pipeline with scaling and logistic regression, evaluate, and log to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672379b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6 — Baseline pipeline and evaluation (manual logging)\n",
    "baseline_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)),\n",
    "])\n",
    "\n",
    "baseline_pipe.fit(X_train, y_train)\n",
    "y_pred = baseline_pipe.predict(X_test)\n",
    "y_proba = baseline_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"f1\": f1_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "print(\"Baseline metrics:\", metrics)\n",
    "\n",
    "# Log baseline into mlflow manually\n",
    "with mlflow.start_run(run_name=\"baseline_logreg\"):\n",
    "    mlflow.log_params({\"model\": \"logistic_regression\", \"max_iter\": 2000})\n",
    "    mlflow.log_metrics(metrics)\n",
    "    # Log classifier as an artifact/model\n",
    "    mlflow.sklearn.log_model(baseline_pipe, \"model\")\n",
    "    # Save and log a small artifact (feature list)\n",
    "    features_path = \"features_baseline.txt\"\n",
    "    with open(features_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(feature_names))\n",
    "    mlflow.log_artifact(features_path)\n",
    "    print(\"Baseline run logged under run id:\", mlflow.active_run().info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddcb454",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Autologging + RandomForest: experiments and hyperparameter search\n",
    "MLflow autologging will record parameters, metrics, artifacts, and the model automatically for scikit-learn.\n",
    "We will:\n",
    "- enable mlflow.sklearn.autolog()\n",
    "- run RandomizedSearchCV\n",
    "- log best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb915a30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7 — Autologging and RandomizedSearchCV\n",
    "mlflow.sklearn.autolog()  # enable autologging for sklearn\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [50, 100, 200, 400],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# We'll wrap training in an MLflow run so autologging ties to this run\n",
    "with mlflow.start_run(run_name=\"rf_random_search\"):\n",
    "    search.fit(X_train, y_train)\n",
    "    best_rf = search.best_estimator_\n",
    "    print(\"Best params:\", search.best_params_)\n",
    "    print(\"Best CV score (roc_auc):\", search.best_score_)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred_rf = best_rf.predict(X_test)\n",
    "    y_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "    test_metrics_rf = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "        \"precision\": precision_score(y_test, y_pred_rf),\n",
    "        \"recall\": recall_score(y_test, y_pred_rf),\n",
    "        \"f1\": f1_score(y_test, y_pred_rf),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba_rf),\n",
    "    }\n",
    "    print(\"Test metrics for best RF:\", test_metrics_rf)\n",
    "    # Note: autolog already recorded parameters and metrics. We can still log custom metrics.\n",
    "    mlflow.log_metrics({f\"test_{k}\": v for k, v in test_metrics_rf.items()})\n",
    "    best_run_id = mlflow.active_run().info.run_id\n",
    "    print(\"RF run logged under run id:\", best_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f3925d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Visualize results (confusion matrix, ROC, PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb262f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8 — Plots: confusion matrix, ROC, PR curve\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=bc.target_names)\n",
    "disp.plot(ax=axes[0], colorbar=False)\n",
    "axes[0].set_title(\"Confusion Matrix (RF)\")\n",
    "\n",
    "# ROC\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba_rf, ax=axes[1])\n",
    "axes[1].set_title(\"ROC Curve (RF)\")\n",
    "\n",
    "# Precision-Recall\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_proba_rf, ax=axes[2])\n",
    "axes[2].set_title(\"Precision-Recall (RF)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115690",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Feature importance (Random Forest)\n",
    "Show top features using feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273903c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 9 — Feature importances\n",
    "importances = best_rf.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "print(\"Top features:\\n\", feat_imp.head(10))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=feat_imp.head(15), y=feat_imp.head(15).index)\n",
    "plt.title(\"Top 15 Feature Importances (RF)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f965ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Save the pipeline + best model to MLflow\n",
    "We typically combine preprocessing + model into a single pipeline for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed51ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 10 — Save final pipeline to MLflow (fixed)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "final_pipeline = make_pipeline(StandardScaler(), best_rf)\n",
    "\n",
    "# Fit the new pipeline on the training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "with mlflow.start_run(run_name=\"rf_final_pipeline\"):\n",
    "    # Log identifying parameters\n",
    "    mlflow.log_params({\n",
    "        \"final_model\": \"random_forest_pipeline\",\n",
    "        \"random_state\": RANDOM_STATE\n",
    "    })\n",
    "\n",
    "    # Log model to MLflow\n",
    "    mlflow.sklearn.log_model(final_pipeline, artifact_path=\"model\")\n",
    "\n",
    "    # Evaluate and log test metrics\n",
    "    y_pred_final = final_pipeline.predict(X_test)\n",
    "    y_proba_final = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "    final_metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_final),\n",
    "        \"precision\": precision_score(y_test, y_pred_final),\n",
    "        \"recall\": recall_score(y_test, y_pred_final),\n",
    "        \"f1\": f1_score(y_test, y_pred_final),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba_final),\n",
    "    }\n",
    "    mlflow.log_metrics({f\"test_{k}\": v for k, v in final_metrics.items()})\n",
    "\n",
    "    print(\"✅ Final pipeline fitted and logged successfully.\")\n",
    "    print(\"Run ID:\", mlflow.active_run().info.run_id)\n",
    "    print(\"Final test metrics:\", final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebdfe7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Load a saved model from MLflow and make predictions\n",
    "Find the run containing the saved `model` artifact and load it for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284299f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 11 — Load model from MLflow and predict (fixed)\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=mlflow.get_tracking_uri())\n",
    "\n",
    "def find_latest_run_by_name(run_name: str):\n",
    "    \"\"\"Find the most recent run by its MLflow run name.\"\"\"\n",
    "    try:\n",
    "        # MLflow 2.x way — use search_runs\n",
    "        experiments = [exp.experiment_id for exp in mlflow.search_experiments()]\n",
    "    except Exception:\n",
    "        # Fallback for older MLflow versions\n",
    "        experiments = [exp.experiment_id for exp in client.list_experiments()]\n",
    "\n",
    "    for exp_id in experiments:\n",
    "        runs = client.search_runs(\n",
    "            [exp_id],\n",
    "            filter_string=f\"tags.mlflow.runName = '{run_name}'\",\n",
    "            order_by=[\"attributes.start_time DESC\"],\n",
    "            max_results=1,\n",
    "        )\n",
    "        if runs:\n",
    "            return runs[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Load model and predict ---\n",
    "run_info = find_latest_run_by_name(\"rf_final_pipeline\")\n",
    "\n",
    "if run_info:\n",
    "    run_id = run_info.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    print(f\"Loading model from: {model_uri}\")\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "    # Test predictions\n",
    "    sample_X = X_test.iloc[:5]\n",
    "    preds = loaded_model.predict(sample_X)\n",
    "    preds_proba = loaded_model.predict_proba(sample_X)[:, 1]\n",
    "    print(\"Predictions:\", preds)\n",
    "    print(\"Probabilities:\", preds_proba)\n",
    "else:\n",
    "    print(\"No run found with that name. You can check run names via mlflow.search_runs().\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.84057,
   "end_time": "2025-11-10T22:06:15.585021",
   "environment_variables": {},
   "exception": true,
   "input_path": "12_classification_mlflow.ipynb",
   "output_path": "/opt/ml/output/data/_12_classification_mlflow.ipynb",
   "parameters": {},
   "start_time": "2025-11-10T22:06:02.744451",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}